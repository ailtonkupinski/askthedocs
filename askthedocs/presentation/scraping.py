"""
Interface de Web Scraping

Este m√≥dulo implementa a interface para scraping de websites,
permitindo aos usu√°rios extrair documenta√ß√£o de URLs e criar
cole√ß√µes locais para uso com o sistema RAG.
"""

import streamlit as st
from service.scraping import ScrapingService

def show():
    """
    Exibe a interface de web scraping.
    
    Funcionalidades:
    - Formul√°rio para inserir URL e nome da cole√ß√£o
    - Execu√ß√£o do scraping usando Firecrawl API
    - Feedback visual do progresso e resultados
    """
    st.header("üîç Web Scraping")

    # Formul√°rio para configura√ß√£o do scraping
    with st.form("scraping_form"):
        url = st.text_input("URL da documenta√ß√£o:")
        collection_name = st.text_input("Nome da documenta√ß√£o:")
        submitted = st.form_submit_button("Iniciar scraping")

    # Processa o scraping quando o formul√°rio √© submetido
    if submitted:
        # Valida√ß√£o dos campos obrigat√≥rios
        if not url or not collection_name:
            st.warning("Preencha a URL e o nome da documenta√ß√£o.")
            return
            
        # Execu√ß√£o do scraping com feedback visual
        with st.spinner("Iniciando scraping..."):
            try:
                scraper = ScrapingService()
                result = scraper.scrape_website(url, collection_name)
                
                # Exibe resultado do scraping
                if result.get("success"):
                    st.success(f"Scraping conclu√≠do com sucesso! Salvos {result['files']} arquivos.")
                else:
                    st.error(f"Erro ao iniciar scraping: {result.get('error', 'desconhecido')}")
            except Exception as e:
                st.error(f"Falha inesperada: {e}")